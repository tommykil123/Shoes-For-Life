{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K-B2xDdI1_td"},"source":["#Settings"]},{"cell_type":"code","metadata":{"id":"wc5eH1Szh25I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607910460214,"user_tz":480,"elapsed":381,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}},"outputId":"f09429c2-eda4-45c0-d7ab-e6276249dd0c"},"source":["%load_ext autoreload\r\n","%autoreload 2\r\n","\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":618,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlugYt3YeH0Z","executionInfo":{"status":"ok","timestamp":1607910465299,"user_tz":480,"elapsed":5453,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}},"outputId":"ff9e3d52-7b88-4c9e-fb36-95c3f4b5d67e"},"source":["#Needed to use cv2.xfeatures2d.SIFT_create() in Segmentation section\r\n","!pip install opencv-python==3.4.2.16\r\n","!pip install opencv-contrib-python==3.4.2.16"],"execution_count":619,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: opencv-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.18.5)\n","Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_BJNisGi-ia","executionInfo":{"status":"ok","timestamp":1607910465462,"user_tz":480,"elapsed":5610,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}},"outputId":"da4a7e95-4c6f-4033-f9fa-635b85ae5cf8"},"source":["import os\r\n","##########################################################\r\n","# SHOULD CHANGE THE PATH WHERE YOU PUT THE SHARED DRIVE!\r\n","# SHARED_DRIVE_LOCATION = 'Academic/2020 Fall/EECS 504/' # Muti\r\n","SHARED_DRIVE_LOCATION = '/content/drive/MyDrive' # Thomas #Junhwan\r\n","##########################################################\r\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = os.path.join(SHARED_DRIVE_LOCATION, '504_project/')\r\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\r\n","# print(os.listdir(GOOGLE_DRIVE_PATH))\r\n","\r\n","import sys\r\n","sys.path.append(GOOGLE_DRIVE_PATH)\r\n","\r\n","import time\r\n","os.environ[\"TZ\"] = \"US/Eastern\"\r\n","time.tzset()\r\n","\r\n","import glob\r\n","\r\n","%cd {os.path.join('/content', GOOGLE_DRIVE_PATH)}\r\n","%ls"],"execution_count":620,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1aDjp-r3-uoqcu-Kzpsu2w2K7MS9dAy7S/504_project\n"," Brainstorm.gdoc                            'Project Proposal.gdoc'\n","'Copy of Final Project.ipynb'               \u001b[0m\u001b[01;34m'Retailer Photos'\u001b[0m/\n","'Final Project.ipynb'                        \u001b[01;34mSegmentation\u001b[0m/\n","'Final Project Presentation Video.gslides'   \u001b[01;34mshoe_detection\u001b[0m/\n","\u001b[01;34m'Meeting Minutes'\u001b[0m/                           \u001b[01;34mStitching\u001b[0m/\n","'Project PPT.pptx'                          \u001b[01;34m'User Photos'\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"syFznOuOA8Sg"},"source":["#Input Paths"]},{"cell_type":"code","metadata":{"id":"UqktmipYA6qJ","executionInfo":{"status":"ok","timestamp":1607910465463,"user_tz":480,"elapsed":5606,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["user_path = \"User Photos/left_right_01.jpg\"  #works 1/2 (detection problem)\r\n","user_path = \"User Photos/left/left21.jpg\"\r\n","user_path = \"User Photos/right/right30.jpg\" #works well 2/2\r\n","user_path = \"User Photos/left/left09.jpg\"\r\n","user_path = \"User Photos/left/left01.jpg\"\r\n","user_path = \"User Photos/right/right36.jpg\"\r\n","user_path = \"User Photos/right/right37.jpg\"\r\n","# \"User Photos/right/right10.jpg\" #works 0/2 (segmentation problem)\r\n","# \"User Photos/left_right_01.jpg\" #works 2/3 (stitching problem)\r\n","# \"User Photos/right/right18.jpg\" #works 1/2 (stitching problem)\r\n","retail_right_path = \"Retailer Photos/Shuoqi Wang/NIKE/37/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Shuoqi Wang/NIKE/37/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/fx2044_black/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/fx2044_black/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/zx_2k_orange/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/zx_2k_orange/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/kaptir_black/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/kaptir_black/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/nmd_r1_v2_pink/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/nmd_r1_v2_pink/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/stan_smith_red/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/stan_smith_red/left.jpg\"\r\n","retail_right_path = \"Retailer Photos/Nam Gyu Kil/Adidas/busenitz_pro_black/right.jpg\"\r\n","retail_left_path = \"Retailer Photos/Nam Gyu Kil/Adidas/busenitz_pro_black/left.jpg\"\r\n"],"execution_count":621,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhZO3k61hJtS"},"source":["# 1. Shoes Detection\r\n","### Input: User Image\r\n","### Output: Cropped Image, Bounding Image"]},{"cell_type":"code","metadata":{"id":"ByTxKg50hPKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607910465633,"user_tz":480,"elapsed":5771,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}},"outputId":"c33df5f0-2dd0-496f-de45-ee78a4040fd5"},"source":["%cd shoe_detection/\r\n","\r\n","from __future__ import division\r\n","\r\n","from models import Darknet\r\n","# from models import *\r\n","from utils.utils import *\r\n","from utils.datasets import *\r\n","from utils.nms_footwear import *\r\n","\r\n","import os\r\n","import sys\r\n","import time\r\n","import datetime\r\n","import argparse\r\n","\r\n","from PIL import Image\r\n","\r\n","import torch\r\n","from torch.utils.data import DataLoader\r\n","from torchvision import datasets\r\n","from torch.autograd import Variable\r\n","import torchvision.transforms as transforms\r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.patches as patches\r\n","from matplotlib.ticker import NullLocator\r\n","\r\n","\r\n","def detect_shoes(image_jpeg, conf_thres=0.1, nms_thres=0.4, box_extension=0):\r\n","    '''Detect shoes in an image.\r\n","    Given an image, detect where the shoes are and output the bounding box coordinates,\r\n","    class confidence scores and confidence score.\r\n","    Input:\r\n","    - img_jpeg: image data read from Image.open(img_path).\r\n","    - conf_thres: confidence score threshold. Float.\r\n","    - nms_thres: threshold for non maximum suppression.\r\n","    Output:\r\n","    - croppend images?\r\n","    - bounding box coordinates\r\n","    - confidence scores\r\n","    '''\r\n","    model_def = 'shoe_detection/config/yolov3-openimages.cfg'\r\n","    weights_path = 'shoe_detection/config/yolov3-openimages.weights'\r\n","    class_path = 'shoe_detection/config/oidv6.names'\r\n","    conf_thres = 0.1\r\n","    nms_thres = 0.4\r\n","    batch_size = 1\r\n","    n_cpu = 0\r\n","    img_size = 416\r\n","\r\n","\r\n","    # Extract image as PyTorch tensor\r\n","    img_np = np.array(image_jpeg)\r\n","\r\n","    img_tnsr = transforms.ToTensor()(image_jpeg)\r\n","    img_shape_original = torch.tensor(img_tnsr.shape)[[1,2,0]]\r\n","\r\n","    # Pad to square resolution\r\n","    img, _ = pad_to_square(img_tnsr, 0)\r\n","    # Resize\r\n","    img = resize(img, img_size)\r\n","    img = img.unsqueeze_(0)\r\n","\r\n","    # Set up device\r\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","\r\n","    # Set up model\r\n","    model = Darknet(model_def, img_size=img_size).to(device)\r\n","    model.load_darknet_weights(weights_path)\r\n","\r\n","    model.eval()  # Set in evaluation mode\r\n","    classes = load_classes(class_path)  # Extracts class labels from file\r\n","    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\r\n","    input_imgs = Variable(img.type(Tensor))\r\n","\r\n","    # Get detections\r\n","    with torch.no_grad():\r\n","        detections = model(input_imgs) # (B, A, )\r\n","        detections = non_max_suppression_for_footwear(detections, conf_thres, nms_thres)[0]\r\n","\r\n","    if detections is not None:\r\n","        detections = rescale_boxes(detections, img_size, img_shape_original[:2])\r\n","        cropped_imgs = []\r\n","        bbox_coords = []\r\n","        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\r\n","            x1 = round(x1.item()) - box_extension\r\n","            y1 = round(y1.item()) - box_extension\r\n","            x2 = round(x2.item()) + box_extension\r\n","            y2 = round(y2.item()) + box_extension\r\n","            # cropped_imgs.append(img_tnsr[:, x1:x2, y1:y2])\r\n","            cropped_imgs.append(img_np[y1:y2, x1:x2, :])\r\n","            bbox_coords.append([x1,y1,x2,y2])\r\n","        return cropped_imgs, bbox_coords\r\n","    else:\r\n","        return None, None\r\n","\r\n","%cd .."],"execution_count":622,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1aDjp-r3-uoqcu-Kzpsu2w2K7MS9dAy7S/504_project/shoe_detection\n","/content/drive/.shortcut-targets-by-id/1aDjp-r3-uoqcu-Kzpsu2w2K7MS9dAy7S/504_project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1gCzfbF7pEuV","colab":{"base_uri":"https://localhost:8080/","height":665},"executionInfo":{"status":"error","timestamp":1607910467037,"user_tz":480,"elapsed":7169,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}},"outputId":"091e48b7-039d-4b4e-cb07-061780a3400a"},"source":["img_path = user_path\r\n","img = Image.open(img_path)\r\n","cropped_imgs, bbox_coords = detect_shoes(img)\r\n","\r\n","plt.figure()\r\n","if len(cropped_imgs) > 1:\r\n","  fig, ax = plt.subplots(1, len(cropped_imgs))\r\n","  for i, img_ in enumerate(cropped_imgs):\r\n","      ax[i].imshow(img_)\r\n","      ax[i].set_axis_off()\r\n","else:\r\n","  plt.axis('off')\r\n","  plt.imshow(cropped_imgs[0])"],"execution_count":623,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-623-b8c4113f8aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;31m# making reliable interpretation impossible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhigh\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m                 _log.warning(\n\u001b[1;32m    709\u001b[0m                     \u001b[0;34m'Clipping input data to the valid range for imshow with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, out, fill_value, keepdims)\u001b[0m\n\u001b[1;32m   5671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5672\u001b[0m             result = self.filled(fill_value).min(\n\u001b[0;32m-> 5673\u001b[0;31m                 axis=axis, out=out, **kwargs).view(type(self))\n\u001b[0m\u001b[1;32m   5674\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5675\u001b[0m                 \u001b[0;31m# Set the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     32\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     33\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n","\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YDwuDUtRhJ1B"},"source":["# 2. Segmentation"]},{"cell_type":"markdown","metadata":{"id":"wSuQdj5ZhdMu"},"source":["## Retail Photo Segmentation\r\n","### Input: Retail Image\r\n","### Output: Mask of the Shoes"]},{"cell_type":"code","metadata":{"id":"pUPxG39EkXtU","executionInfo":{"status":"aborted","timestamp":1607910467031,"user_tz":480,"elapsed":7153,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["def retail_segment(image_path):\r\n","  shoes = plt.imread(image_path)/255\r\n","  shoes = shoes[:,:,:3]\r\n","  ind_shoes = np.where(np.all(shoes == shoes[0,0], axis=-1))\r\n","  ind_not_shoes = np.where(np.all(shoes != shoes[0,0], axis=-1))\r\n","  mask_shoes = np.copy(shoes)\r\n","  mask_shoes[ind_shoes[0], ind_shoes[1],:] = 0\r\n","  mask_shoes[ind_not_shoes[0], ind_not_shoes[1],:] = 1\r\n","  return mask_shoes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yabiGg1YDf1J","executionInfo":{"status":"aborted","timestamp":1607910467032,"user_tz":480,"elapsed":7147,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["img_path = retail_right_path\r\n","img_retail_seg = retail_segment(img_path)\r\n","plt.imshow(img_retail_seg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aekFfrVR-dYf"},"source":["Alternative Method:\n"]},{"cell_type":"code","metadata":{"id":"mVFGtMW9-qgU","executionInfo":{"status":"aborted","timestamp":1607910467035,"user_tz":480,"elapsed":7147,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.signal\n","import scipy\n","from skimage import segmentation\n","from skimage import io, color\n","import skimage\n","\n","def cluster_centers(superpixel_map):\n","  x_centers = np.zeros(len(np.unique(superpixel_map)))\n","  y_centers = np.zeros_like(x_centers)\n","  counts = np.zeros_like(x_centers)\n","  rows, cols = superpixel_map.shape\n","\n","  for row in range(rows):\n","    for col in range(cols):\n","      x_centers[superpixel_map[row, col]] += col\n","      y_centers[superpixel_map[row, col]] += row\n","      counts[superpixel_map[row, col]] += 1\n","\n","  x_centers = np.round(x_centers/counts).astype('int')\n","  y_centers = np.round(y_centers/counts).astype('int')\n","  centers = list(zip(y_centers, x_centers))\n","\n","  return centers\n","\n","def apply_supermap(img, superpixel_map):\n","  centers = cluster_centers(superpixel_map)\n","  out = np.copy(img)\n","  for i,(row, col) in enumerate(centers):\n","    if img[row,col,0] > 0.92 and img[row,col,1] > 0.92 and img[row,col,2] > 0.92 and img[row,col,0] == img[row,col,1] and img[row,col,2] ==img[row,col,1]:\n","      out[superpixel_map == i] = [1,1,1]\n","    else:\n","      out[superpixel_map == i] = [0,0,0]\n","  return out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nvm5b4o-_7LD","executionInfo":{"status":"aborted","timestamp":1607910467035,"user_tz":480,"elapsed":7144,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["from PIL import Image\n","\n","left = plt.imread(retail_left_path)/255\n","left = left[:,:,:3]\n","super_left = segmentation.slic(left, n_segments=82, compactness=30, max_iter=20)\n","right = plt.imread(retail_right_path)/255\n","right = right[:,:,:3]\n","super_right = segmentation.slic(right, n_segments=82, compactness=30, max_iter=20)\n","fig, ax = plt.subplots(2, 3, figsize=(8,8))\n","images = [left, right]\n","maps = [super_left, super_right]\n","for i,a in enumerate(ax):\n","  a[0].set_axis_off()\n","  a[0].set_title('Original', fontsize=10)\n","  a[0].imshow(images[i])\n","  a[1].set_axis_off()\n","  a[1].set_title('Superpixel map', fontsize=10)\n","  a[1].imshow(skimage.color.label2rgb(maps[i]))\n","  a[2].set_axis_off()\n","  a[2].set_title('Shoe Mask', fontsize=10)\n","  a[2].imshow(apply_supermap(images[i], maps[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oC5ojKBghgN9"},"source":["## User Photo Segmentation\r\n","### Input: Image, Cropped Image, Bounding Box\r\n","### Outut: Mask of the Shoes"]},{"cell_type":"code","metadata":{"id":"rhVn3lSCDZFf","executionInfo":{"status":"aborted","timestamp":1607910467036,"user_tz":480,"elapsed":7142,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["#!pip install opencv-python==3.4.2.16\r\n","#!pip install opencv-contrib-python==3.4.2.16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WqkhM4Czvlv","executionInfo":{"status":"aborted","timestamp":1607910467036,"user_tz":480,"elapsed":7139,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["from scipy.spatial import ConvexHull, convex_hull_plot_2d\r\n","from skimage.draw import polygon\r\n","import cv2 as cv\r\n","import pdb \r\n","\r\n","def user_segment(img, b_super=False, b_blur=False, blur=15):\r\n","  if b_super == True:\r\n","    super_img = segmentation.slic(img, n_segments=10000, compactness=15, max_iter=20)\r\n","    img = apply_supermap(img, super_img)\r\n","  # SIFT\r\n","  gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\r\n","  sift  = cv.xfeatures2d.SIFT_create()\r\n","  keypoints,descriptors = sift.detectAndCompute(gray,None)   #calculate keypoints and their orientation\r\n","  # Convex\r\n","  pts = np.zeros((len(keypoints),2))\r\n","  for i in range(len(keypoints)):\r\n","    pts[i,0] = int(keypoints[i].pt[0])\r\n","    pts[i,1] = int(keypoints[i].pt[1])\r\n","  # Convex Hull\r\n","  hull = ConvexHull(pts, True)\r\n","  hull_indices = hull.vertices\r\n","  new_x, new_y = polygon(pts[hull_indices,0],pts[hull_indices,1])\r\n","  # Grab Cut\r\n","  mask = np.ones(img.shape[:2],np.uint8) * 2\r\n","  mask[new_y, new_x] = 3\r\n","  bgdModel = np.zeros((1,65),np.float64)\r\n","  fgdModel = np.zeros((1,65),np.float64)\r\n","  rect = (1,1,img.shape[0]-1,img.shape[1]-1)\r\n","  if b_blur == True:\r\n","    img = cv.GaussianBlur(img,(blur,blur),0)\r\n","    # img = cv.bilateralFilter(img,9,75,75)\r\n","  cv.grabCut(img,mask,rect,bgdModel,fgdModel,10,cv.GC_INIT_WITH_MASK)\r\n","  mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\r\n","  return mask2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZW2ERl0Z0PWy","executionInfo":{"status":"aborted","timestamp":1607910467036,"user_tz":480,"elapsed":7135,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["img_user_seg = cropped_imgs[1]\r\n","mask = user_segment(img_user_seg)\r\n","#img_user_seg = img*mask[:,:,np.newaxis]\r\n","plt.imshow(mask, cmap = 'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zq-ctMa0hJ8I"},"source":["# 3. Stitching\r\n","### Input: User Image, Cropped Images, Bounding Boxes, Retailer Images, Mask of User and Retailer Shoes\r\n","### Output: User Photo with Retailer Shoes Stitched"]},{"cell_type":"markdown","metadata":{"id":"-o2zRQXF8EdV"},"source":["## Photo Class used for Stitching"]},{"cell_type":"code","metadata":{"id":"xCpM9nYlhD0U","executionInfo":{"status":"aborted","timestamp":1607910467247,"user_tz":480,"elapsed":7343,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["import numpy as np\r\n","import cv2\r\n","import copy\r\n","\r\n","class Photo:\r\n","  inv_val = -1\r\n","\r\n","  def __init__(self, photo, seg_map, name=\"NoName\"):\r\n","    self.original = photo\r\n","    self.seg_map = seg_map\r\n","    self.height, self.width, self.channel = photo.shape\r\n","    self.name = name  \r\n","  \r\n","\r\n","  def add_padding(self, final_height, final_width):\r\n","    self.pad_left = (final_width - self.width)//2\r\n","    self.pad_right = final_width - self.width - self.pad_left\r\n","    self.pad_top = (final_height - self.height)//2\r\n","    self.pad_bottom = final_height - self.height - self.pad_top\r\n","    \r\n","    self.padded = cv2.copyMakeBorder(self.original,\r\n","                                    self.pad_top,self.pad_bottom,self.pad_left,self.pad_right,\r\n","                                    cv2.BORDER_CONSTANT,value=[0,0,0])\r\n","    \r\n","    self.seg_map = self.seg_map.astype('float32')\r\n","    self.padded_seg_map = cv2.copyMakeBorder(self.seg_map,\r\n","                                             self.pad_top,self.pad_bottom,self.pad_left,self.pad_right,\r\n","                                             cv2.BORDER_CONSTANT,value=[0])\r\n","    \r\n","    self.padded_height = final_height\r\n","    self.padded_width = final_width\r\n","\r\n","\r\n","  def largest_eigvec(self):\r\n","    #create 2 x N array\r\n","    Y, X = self.seg_map.nonzero() # (row# = Y) (col# = X)\r\n","    coords = np.zeros((2, len(X)))\r\n","    coords[0, :] = np.array(X)\r\n","    coords[1, :] = np.array(Y)\r\n","    avg = np.mean(coords, axis=1)\r\n","    coords = coords - avg.reshape(2, 1) #make it 0-mean\r\n","\r\n","    u, s, vh = np.linalg.svd(coords, full_matrices=False)\r\n","    largest = np.argmax(s) #index of largest eigval\r\n","    self.eigvec = u[largest, :] #largest eigval for covarianace matrix (row of U)\r\n","\r\n","    if self.eigvec[0] < 0: #also in largest_eigvec function, but for atomicity/redundancy\r\n","      self.eigvec *= -1\r\n","\r\n","    return self.eigvec\r\n","  \r\n","\r\n","  def _get_rotation_mat(self, alternative = False):\r\n","    #two different rotation is possible since we are matching a line to a line\r\n","    #use alternative= True/False to get both orientation matchings\r\n","    eigvec = self.largest_eigvec()\r\n","    if eigvec[0] < 0: #also in largest_eigvec function, but for atomicity/ redundancy\r\n","      eigvec *= -1\r\n","    if alternative:\r\n","      eigvec = -1*eigvec\r\n","    ax_vec = np.array([1,0])\r\n","    theta = np.arccos(np.dot(eigvec, ax_vec))\r\n","    direction = np.sign(eigvec[1])\r\n","    if alternative:\r\n","      self.angle_alt = direction*theta*180/np.pi\r\n","      return cv2.getRotationMatrix2D((self.padded_width/2,self.padded_height/2), self.angle_alt, 1)\r\n","    else:\r\n","      self.angle = direction*theta*180/np.pi\r\n","      return cv2.getRotationMatrix2D((self.padded_width/2,self.padded_height/2), self.angle, 1)\r\n","  \r\n","\r\n","  def _rotate_seg_map(self, seg_map, transform_m, is_homography=False):\r\n","    tmp_seg = copy.deepcopy(seg_map).astype('float32')\r\n","    if is_homography:\r\n","      tmp_seg = cv2.warpPerspective(tmp_seg, transform_m, (self.padded_width, self.padded_height))\r\n","    else:\r\n","      tmp_seg = cv2.warpAffine(tmp_seg, transform_m, (self.padded_width, self.padded_height))\r\n","    return tmp_seg\r\n","\r\n","\r\n","  def align_eigvec(self, alternative = False):\r\n","    rotation_M = self._get_rotation_mat(alternative)\r\n","    if alternative:\r\n","      self.oriented_alt = cv2.warpAffine(self.padded, rotation_M, (self.padded_width, self.padded_height))\r\n","      self.seg_oriented_alt = self._rotate_seg_map(self.padded_seg_map, rotation_M)\r\n","    else:\r\n","      self.oriented = cv2.warpAffine(self.padded, rotation_M, (self.padded_width, self.padded_height))\r\n","      self.seg_oriented = self._rotate_seg_map(self.padded_seg_map, rotation_M)\r\n","  \r\n","\r\n","  def _find_bbox(self, alternative = False):\r\n","    Y, X = None, None\r\n","    if alternative:\r\n","      Y, X = self.seg_oriented_alt.nonzero()\r\n","    else:\r\n","      Y, X = self.seg_oriented.nonzero()\r\n","    leftmost = np.min(X)\r\n","    rightmost = np.max(X)\r\n","    topmost = np.max(Y)\r\n","    bottommost = np.min(Y)\r\n","    return topmost, bottommost, leftmost, rightmost\r\n","\r\n","\r\n","  def contour_slices(self, alternative = False, num_slices = 10):\r\n","    tmp_seg = None\r\n","    if alternative:\r\n","      seg_map = self.seg_oriented_alt\r\n","    else:\r\n","      seg_map = self.seg_oriented\r\n","    \r\n","    topmost, bottommost, leftmost, rightmost = self._find_bbox(alternative)\r\n","\r\n","    #use empty array instead of fixed size so that slices with no intersection can be left out\r\n","    X = [] \r\n","    Y = []\r\n","    h_interval = (rightmost-leftmost)/(num_slices+1) #double\r\n","    for i in range(num_slices):\r\n","      slice_pos = int(leftmost + h_interval*(i+1)) #integer value\r\n","      y_vals = seg_map[:, slice_pos].nonzero()[0]\r\n","      if y_vals.size == 0:\r\n","        #insert inv_val so that datapoints that should have\r\n","        #corresponded to this slice can be disregarded from the other image\r\n","        X.append(Photo.inv_val)\r\n","        Y.append(Photo.inv_val)\r\n","        X.append(Photo.inv_val)\r\n","        Y.append(Photo.inv_val)\r\n","        continue\r\n","      X.append(slice_pos)\r\n","      Y.append(np.min(y_vals)) #lowest contour intersection\r\n","      X.append(slice_pos)\r\n","      Y.append(np.max(y_vals)) #highest contour intersection\r\n","    \r\n","    #fewer slices since sneakers are more wide than tall\r\n","    num_slices //= 2\r\n","    v_interval = (topmost-bottommost)/(num_slices+1) #double\r\n","    X_h = np.zeros(num_slices*2)\r\n","    Y_h = np.zeros(num_slices*2)\r\n","    for i in range(num_slices):\r\n","      slice_pos = int(bottommost + v_interval*(i+1)) #integer value\r\n","      x_vals = seg_map[slice_pos, :].nonzero()[0]\r\n","      if x_vals.size == 0:\r\n","        X.append(Photo.inv_val)\r\n","        Y.append(Photo.inv_val)\r\n","        X.append(Photo.inv_val)\r\n","        Y.append(Photo.inv_val)\r\n","        continue\r\n","      Y.append(slice_pos)\r\n","      X.append(np.min(x_vals)) #leftmost contour intersection\r\n","      Y.append(slice_pos)\r\n","      X.append(np.max(x_vals)) #rightmost contour intersection\r\n","\r\n","    X = np.array(X)\r\n","    Y = np.array(Y)\r\n","\r\n","    if alternative:\r\n","      self.X_alt, self.Y_alt = X,Y\r\n","    else:\r\n","      self.X, self.Y = X,Y\r\n","\r\n","    return X, Y\r\n","  \r\n","\r\n","  def homography_transform(self, homography_m):\r\n","    self.transformed = cv2.warpPerspective(self.oriented, homography_m, (self.padded_width, self.padded_height))\r\n","    self.seg_transformed = self._rotate_seg_map(self.seg_oriented, homography_m, True)\r\n","  \r\n","\r\n","  def affine_transform(self, affine_m):\r\n","    self.transformed = cv2.warpAffine(self.oriented, affine_m, (self.padded_width, self.padded_height))\r\n","    self.seg_transformed = self._rotate_seg_map(self.seg_oriented, affine_m)\r\n","\r\n","\r\n","  def stitch_n_crop(self, other_photo, transform_m, is_homography=False, alternative=False, filter = False):\r\n","    #if filter = True, mask using current photo's segmentation map to account for occlusion (optional)\r\n","\r\n","    #added because we need other_photo.transformed to be most up to date every time\r\n","    #stitch_n_crop is called\r\n","    if is_homography:\r\n","      other_photo.homography_transform(transform_m)\r\n","    else:\r\n","      other_photo.affine_transform(transform_m)\r\n","\r\n","    #rotate other_photo to this photo's original orientation\r\n","    reverse_rot_M = None\r\n","    if alternative:\r\n","      reverse_rot_M = cv2.getRotationMatrix2D((self.padded_width/2,self.padded_height/2), -self.angle_alt, 1) #Note: negative angle\r\n","    else:\r\n","      reverse_rot_M = cv2.getRotationMatrix2D((self.padded_width/2,self.padded_height/2), -self.angle, 1) #Note: negative angle\r\n","    other_complete = cv2.warpAffine(other_photo.transformed, reverse_rot_M, (self.padded_width,self.padded_height))\r\n","    other_seg_complete = self._rotate_seg_map(other_photo.seg_transformed, reverse_rot_M)\r\n","\r\n","    #crop out padding\r\n","    other_complete = other_complete[self.pad_top:self.pad_top+self.height, self.pad_left:self.pad_left+self.width, :]\r\n","    other_seg_complete = other_seg_complete[self.pad_top:self.pad_top+self.height, self.pad_left:self.pad_left+self.width] != 0\r\n","    #other_seg_complete needs != 0 because not all values in segmentationmap are 0/1's due to homography transformation and rotation\r\n","\r\n","    #paste it current photo\r\n","    self.complete = copy.deepcopy(self.original)\r\n","    for i in range(self.channel):\r\n","      if filter:\r\n","        self.complete[:,:,i][(other_seg_complete != 0) & (self.seg_map != 0)] = other_complete[:,:,i][(other_seg_complete != 0) & (self.seg_map != 0)]\r\n","      else:\r\n","        self.complete[:,:,i][other_seg_complete] = other_complete[:,:,i][other_seg_complete]\r\n","    \r\n","    return copy.deepcopy(self.complete), other_seg_complete"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHyGBHWr8PV-"},"source":["##Stitching"]},{"cell_type":"code","metadata":{"id":"atrZ-KVmwxqd","executionInfo":{"status":"aborted","timestamp":1607910467248,"user_tz":480,"elapsed":7340,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["retail_paths = [retail_right_path, retail_left_path]\r\n","retail_names = [\"right\", \"left\"]\r\n","retail_lst = [] #list of retail Photo class\r\n","\r\n","for path, name in zip(retail_paths, retail_names):\r\n","  img = plt.imread(path)\r\n","  seg = retail_segment(path)[:,:,0]\r\n","  retail_lst.append(Photo(img, seg, name=name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJJE8chv8Q_k","executionInfo":{"status":"aborted","timestamp":1607910467249,"user_tz":480,"elapsed":7338,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["user_photo = plt.imread(user_path) #user photo which stitchings will be accumulated\r\n","user_photo = copy.deepcopy(user_photo)\r\n","\r\n","#cropped_imgs, bbox_coords = detect_shoes(user) #already ran in section 1\r\n","\r\n","#Considers upside down orientations when including True\r\n","alternative_lst = [True, False]\r\n","\r\n","for i, (user_shoe, bbox) in enumerate(zip(cropped_imgs, bbox_coords)):\r\n","  user_seg = user_segment(user_shoe)\r\n","\r\n","  #prevent bad segmentations from overwriting good stitchings/ break code\r\n","  seg_size_threshold = 0.3 #min percentage shoe must take up of the bounding box\r\n","  if np.sum(user_seg != 0) / user_seg.size < seg_size_threshold:\r\n","    continue\r\n","\r\n","  user = Photo(user_shoe, user_seg)\r\n","\r\n","  #################\r\n","  #Pad images to make all the same sizes\r\n","  #################\r\n","  #find largest width and height\r\n","  max_height, max_width = 0,0\r\n","\r\n","  for retail in retail_lst:\r\n","    max_height = max(max_height, retail.height)\r\n","    max_width = max(max_width, retail.width)\r\n","  max_height = max(max_height, user.height)\r\n","  max_width = max(max_width, user.width)\r\n","\r\n","  #pad retail photos\r\n","  for retail in retail_lst:\r\n","    retail.add_padding(max_height, max_width)\r\n","  #pad user photo\r\n","  user.add_padding(max_height, max_width)\r\n","\r\n","\r\n","  #################\r\n","  #Align shoes by their largest eigenvector\r\n","  #Then slice their contours\r\n","  #################\r\n","  num_slices = 20\r\n","  for retail in retail_lst:\r\n","    retail.align_eigvec()\r\n","    retail.contour_slices(num_slices = num_slices)\r\n","  for alt in alternative_lst:\r\n","    user.align_eigvec(alt)\r\n","    user.contour_slices(num_slices = num_slices, alternative = alt)\r\n","\r\n","  #################\r\n","  #Pick best matching similarity and homography transform \r\n","  #using RANSAC and least squares error\r\n","  #################\r\n","  transform_types = [\"similarity\", \"homography\"]\r\n","  min_homography_tuple = () #retail, alt(True/False), homography_m\r\n","  min_similarity_tuple = () #retail, alt(True/False), affine_m\r\n","  for t_type in transform_types:\r\n","    min_cost = math.inf\r\n","    max_inliers = 0\r\n","    for retail in retail_lst:\r\n","      retail_contour_X, retail_contour_Y = retail.X, retail.Y\r\n","      src = np.vstack((retail_contour_X, retail_contour_Y)).T\r\n","      for alt in alternative_lst:\r\n","        user_contour_X, user_contour_Y = None, None\r\n","        if alt:\r\n","          user_contour_X, user_contour_Y = user.X_alt, user.Y_alt\r\n","        else:\r\n","          user_contour_X, user_contour_Y = user.X, user.Y\r\n","\r\n","        #find transformation matrix\r\n","        dst = np.vstack((user_contour_X, user_contour_Y)).T\r\n","        transform_m, inliers = None, None\r\n","        src_filtered = src[dst != Photo.inv_val].reshape((-1, 2))\r\n","        dst_filtered = dst[dst != Photo.inv_val].reshape((-1, 2))\r\n","        if t_type == \"homography\":\r\n","          transform_m, inliers = cv2.findHomography(src_filtered, dst_filtered)\r\n","        elif t_type == \"similarity\":\r\n","          transform_m, inliers = cv2.estimateAffinePartial2D(src_filtered, dst_filtered)\r\n","        inliers_mask = np.vstack((inliers, inliers)).reshape(2, -1) == 1\r\n","\r\n","        #calculate cost = sum(||Hx-y||^2)\r\n","        src_3D = np.vstack((src_filtered.T, np.ones(len(src_filtered))))\r\n","        mapped = np.matmul(transform_m, src_3D)\r\n","        if t_type == \"homography\":\r\n","          mapped[0, :] = mapped[0, :] / mapped[2, :]\r\n","          mapped[1, :] = mapped[1, :] / mapped[2, :]\r\n","        dst_filtered = dst_filtered.T\r\n","        cost = np.sum((mapped[:2, :][inliers_mask] - dst_filtered[inliers_mask])**2)\r\n","        num_inliers = np.count_nonzero(inliers)\r\n","\r\n","        #pick first by num_inliers, then by cost\r\n","        if cost < min_cost and max_inliers <= num_inliers:\r\n","          if t_type == \"homography\":\r\n","            min_homography_tuple = (retail, alt, transform_m)\r\n","          elif t_type == \"similarity\":\r\n","            min_similarity_tuple = (retail, alt, transform_m)\r\n","          min_cost = cost\r\n","          max_inliers = num_inliers\r\n","        #print(\"user_{}\".format(i), t_type, retail.name, alt, cost, num_inliers)\r\n","\r\n","  #################\r\n","  #Pick the better matching transformation to apply\r\n","  #based on stitching results\r\n","  #################\r\n","  retail_h, alt_h, homography_m = min_homography_tuple\r\n","  homography_final, homography_seg = user.stitch_n_crop(retail_h, homography_m, is_homography=True, alternative=alt_h)\r\n","\r\n","  retail_a, alt_a, affine_m = min_similarity_tuple\r\n","  affine_final, affine_seg = user.stitch_n_crop(retail_a, affine_m, alternative=alt_a) # this affect user's member vairables\r\n","\r\n","  #pick the option where retail segmentaion covers more of user segmentation\r\n","  better_option = \"\"\r\n","  final = None\r\n","  overlap_count = 0\r\n","  if np.count_nonzero(user.seg_map[homography_seg]) < np.count_nonzero(user.seg_map[affine_seg]):\r\n","    better_option = \"similarity\"\r\n","    final = affine_final\r\n","    overlap_count = np.count_nonzero(user.seg_map[affine_seg])\r\n","  else:\r\n","    better_option = \"homography\"\r\n","    final = homography_final\r\n","    overlap_count = np.count_nonzero(user.seg_map[homography_seg])\r\n","  #print(better_option)\r\n","\r\n","  #decide to filter by user segmentation if retail overflows by a certain threshold\r\n","  #i.e. (overlap between segmentations) / (retail segementation size) < threshold\r\n","  threshold = 0.8\r\n","  if better_option == \"similarity\" and overlap_count/ np.count_nonzero(affine_seg) < threshold:\r\n","    final, _ = user.stitch_n_crop(retail_a, affine_m, alternative=alt_a, filter=True)\r\n","  elif better_option == \"homography\" and overlap_count/ np.count_nonzero(homography_seg) < threshold:\r\n","    final, _ = user.stitch_n_crop(retail_h, homography_m, is_homography=True, alternative=alt_h, filter=True)\r\n","\r\n","  #################\r\n","  #paste the stitched image back to the larger user photo\r\n","  #################\r\n","  x1,y1,x2,y2 = bbox\r\n","  user_photo[y1:y2, x1:x2] = final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzqU1rql6oft"},"source":["#4. Visualize Final Result"]},{"cell_type":"code","metadata":{"id":"USGzRBDK6pG_","executionInfo":{"status":"aborted","timestamp":1607910467249,"user_tz":480,"elapsed":7335,"user":{"displayName":"Nam Gyu Kil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1yOHvtdr0m4cMuGcEPb9n0ytGg7r9HNnVaQo=s64","userId":"08278423732697661539"}}},"source":["original = plt.imread(user_path)\r\n","\r\n","rows, cols, _ = original.shape\r\n","fig, ax = plt.subplots(1,2, figsize=(cols//30,rows//30))\r\n","ax[0].imshow(original)\r\n","ax[1].imshow(user_photo)\r\n","for x in ax:\r\n","  x.set_axis_off()\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}